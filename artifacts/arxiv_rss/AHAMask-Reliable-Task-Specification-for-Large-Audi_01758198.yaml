title: 'AHAMask: Reliable Task Specification for Large Audio Language Models without
  Instructions'
url: https://arxiv.org/abs/2509.01787
source: arxiv_rss
type: paper
date_discovered: '2025-12-02T10:07:18.686590+00:00'
date_seen: '2025-12-02'
metadata:
  arxiv_id: '2509.01787'
  published: Tue, 02 Dec 2025 00:00:00 -0500
  authors: Unknown
  categories: eess.AS, cs.AI, cs.SD
content_preview: 'Title: AHAMask: Reliable Task Specification for Large Audio Language
  Models without Instructions


  Authors: Unknown


  Abstract:

  Although current large audio language models (LALMs) extend text large language
  models (LLMs) with generic acoustic understanding abilities, they usually suffer
  from prompt sensitivity, where different instructions of the same intention can
  yield drastically different outcomes. In this work, we propose AHAMask, where we
  simply mask some of the attention heads in the decod'
content_length: 1199
llm_content_sent: 1199
relevance_checked: true
is_relevant: false
relevance_score: 0.2
reason: Статья посвящена большим аудио-языковым моделям (LALM) и методам управления
  их поведением через маскирование внимания, но не касается синтеза речи. Хотя работа
  связана с аудио-обработкой, она фокусируется на понимании и анализе аудио, а не
  на генерации речи, эмоциональном синтезе или дублировании.
