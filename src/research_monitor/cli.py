"""CLI entry point for research monitor."""

import asyncio
from datetime import date, datetime, timedelta
from pathlib import Path
from typing import Optional

import typer

from research_monitor.adapters.digest import MarkdownDigestGenerator
from research_monitor.adapters.llm import ClaudeClient
from research_monitor.adapters.notifications import SlackNotifier
from research_monitor.adapters.sources import (
    ArXivRSSSource,
    GitHubSource,
    HFPapersSource,
    HFTrendingSource,
)
from research_monitor.config import get_settings
from research_monitor.core import SeenItemsTracker
from research_monitor.use_cases import DigestService, MonitoringService


def main(
    days: int = 1,
    output: Optional[Path] = None,
    debug: bool = False,
    no_slack: bool = typer.Option(False, "--no-slack", help="Disable Slack notifications"),
) -> None:
    """Monitor speech synthesis research updates and generate digest."""
    asyncio.run(async_run(days, output, debug, no_slack))


def app() -> None:
    """CLI entry point."""
    typer.run(main)


async def async_run(days: int, output: Optional[Path], debug: bool, no_slack: bool) -> None:
    """Async implementation of run command."""
    settings = get_settings()
    
    # Header
    print("\n" + "=" * 70)
    print("üéôÔ∏è  RESEARCH MONITOR - Speech Synthesis Updates")
    print("=" * 70)
    
    # Show credentials status
    print(f"\nüîë –ö—Ä–µ–¥—ã:")
    if settings.anthropic_api_key:
        print(f"  ‚úì ANTHROPIC_API_KEY - –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Claude")
    else:
        print(f"  ‚úó ANTHROPIC_API_KEY - –Ω–µ –Ω–∞–π–¥–µ–Ω (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å)")
    
    if settings.github_token:
        print(f"  ‚úì GitHub Token - –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ GitHub feed")
    else:
        print(f"  ‚ö†Ô∏è  GitHub Token - –Ω–µ –Ω–∞–π–¥–µ–Ω (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π rate limit)")
    
    if no_slack:
        print(f"  ‚ö†Ô∏è  SLACK_WEBHOOK_URL - –æ—Ç–∫–ª—é—á–µ–Ω –æ–ø—Ü–∏–µ–π --no-slack")
    elif settings.slack_webhook_url:
        print(f"  ‚úì SLACK_WEBHOOK_URL - –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
    else:
        print(f"  ‚ö†Ô∏è  SLACK_WEBHOOK_URL - –Ω–µ –Ω–∞–π–¥–µ–Ω (—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã)")
    
    # Calculate date range
    since = date.today() - timedelta(days=days)
    digest_date = date.today()
    
    print(f"\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∏:")
    print(f"  ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {since.strftime('%d.%m.%Y')} - {digest_date.strftime('%d.%m.%Y')} ({days} –¥–Ω.)")
    print(f"  ‚Ä¢ –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {settings.relevance_threshold:.0%}")
    print(f"  ‚Ä¢ –ú–∞–∫—Å. —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫: {settings.max_items_per_source}")
    
    if debug:
        print(f"  ‚Ä¢ üîç Debug mode: {settings.debug_dir}")
    
    # Initialize sources
    sources = []
    
    # Get shared keywords for filtering
    speech_keywords = settings.speech_keywords
    
    # ArXiv RSS (if enabled)
    if settings.arxiv_enabled:
        sources.append(
            ArXivRSSSource(
                categories=settings.arxiv_categories,
                max_items=settings.arxiv_max_items,
                filter_by_keywords=settings.arxiv_filter_by_keywords,
                keywords=speech_keywords,
            )
        )
    
    # GitHub
    sources.append(
        GitHubSource(
            token=settings.github_token,
            max_items=settings.max_items_per_source,
            topics=settings.github_topics,
            keywords=settings.github_keywords,
            search_days=settings.github_search_days,
            min_stars=settings.github_min_stars,
            request_delay=settings.github_request_delay,
        )
    )
    
    # HuggingFace Papers
    sources.append(
        HFPapersSource(
            max_items=settings.max_items_per_source,
            search_days=settings.hf_papers_search_days,
            keywords=speech_keywords,
        )
    )
    
    # HuggingFace Trending
    sources.append(
        HFTrendingSource(
            max_items=settings.max_items_per_source,
            max_days_old=settings.hf_models_max_days_old
        )
    )
    
    print(f"\nüì° –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
    for source in sources:
        emoji = getattr(source, 'emoji', '‚Ä¢')
        name = getattr(source, 'name', source.__class__.__name__)
        print(f"  {emoji} {name}")
    
    # Initialize LLM client
    llm_client = ClaudeClient(settings)
    
    # Initialize seen items tracker
    seen_tracker = SeenItemsTracker(settings.artifacts_dir)
    
    # Initialize services
    monitoring_service = MonitoringService(
        sources=sources,
        llm_client=llm_client,
        interests="",  # Not used anymore, prompts are in config
        relevance_threshold=settings.relevance_threshold,
        debug_dir=settings.debug_dir if debug else None,
        seen_tracker=seen_tracker,
    )
    
    digest_generator = MarkdownDigestGenerator()
    
    # Initialize notification service if webhook is configured and not disabled
    notification_service = SlackNotifier(settings.slack_webhook_url) if (settings.slack_webhook_url and not no_slack) else None
    
    digest_service = DigestService(
        llm_client=llm_client,
        digest_generator=digest_generator,
        notification_service=notification_service,
    )
    
    # Collect and filter items
    relevant_results, all_filter_results = await monitoring_service.collect_and_filter(since)
    
    if not relevant_results:
        print("\n" + "=" * 70)
        print("‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û –†–ï–õ–ï–í–ê–ù–¢–ù–´–• –ú–ê–¢–ï–†–ò–ê–õ–û–í")
        print("=" * 70)
        
        # Still save artifacts even if nothing relevant
        if all_filter_results:
            monitoring_service.save_artifacts(all_filter_results)
        
        return
    
    # Generate digest
    print("\n" + "=" * 70)
    print("üìù –≠–¢–ê–ü 4: –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ô–î–ñ–ï–°–¢–ê")
    print("=" * 70)
    print(f"–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –∏ —Ö–∞–π–ª–∞–π—Ç–æ–≤ –¥–ª—è {len(relevant_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤...")
    
    digest, entries = await digest_service.generate_digest(relevant_results, digest_date)
    
    # Save digest
    if output is None:
        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        output = settings.full_digests_dir / f"{timestamp}_digest.md"
    
    digest_service.save_digest(digest, output)
    
    # Generate digest summary
    print("\n" + "=" * 70)
    print("‚ú® –≠–¢–ê–ü 5: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–†–ê–¢–ö–û–ì–û –°–ê–ú–ú–ê–†–ò")
    print("=" * 70)
    print(f"–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ –≤ —Å—Ç–∏–ª–µ Telegram-–∫–∞–Ω–∞–ª–æ–≤...")
    
    try:
        digest_summary = await digest_service.generate_digest_summary(entries)
        
        # Save digest summary to summary directory with same timestamp
        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        summary_output = settings.summary_digests_dir / f"{timestamp}_summary.md"
        digest_service.save_digest(digest_summary, summary_output)
        print(f"‚úì –°–∞–º–º–∞—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {summary_output}")
        
        # Send notification if configured
        if notification_service:
            await digest_service.send_notification(digest_summary, digest_date)
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏: {e}")
    
    # Save artifacts ONLY after successful digest generation
    monitoring_service.save_artifacts(all_filter_results)
    
    print("\n" + "=" * 70)
    print(f"‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 70)
    print(f"üìÑ –î–∞–π–¥–∂–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output}")
    if 'summary_output' in locals():
        print(f"‚ú® –°–∞–º–º–∞—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {summary_output}")
    if debug:
        print(f"üîç Debug –¥–∞–Ω–Ω—ã–µ: {settings.debug_dir}/")
    print()


if __name__ == "__main__":
    app()

